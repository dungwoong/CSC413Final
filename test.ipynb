{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 971,
     "status": "ok",
     "timestamp": 1681323814394,
     "user": {
      "displayName": "Chang Yuan",
      "userId": "10478036312829595539"
     },
     "user_tz": 240
    },
    "id": "4jAfU0hauoPw",
    "outputId": "0b9fd47f-bacd-4763-c3da-b7b2aa7af222"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CSC413Final'...\n",
      "remote: Enumerating objects: 170, done.\u001b[K\n",
      "remote: Counting objects: 100% (170/170), done.\u001b[K\n",
      "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
      "remote: Total 170 (delta 74), reused 126 (delta 34), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (170/170), 2.48 MiB | 9.00 MiB/s, done.\n",
      "Resolving deltas: 100% (74/74), done.\n",
      "/content/CSC413Final\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/dungwoong/CSC413Final.git\n",
    "%cd CSC413Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyuan\\Documents\\CSC413FinalProject\\CSC413Final\\CSC413Final\n"
     ]
    }
   ],
   "source": [
    "# %cd \"C:\\Users\\cyuan\\Documents\\CSC413FinalProject\\CSC413Final\\CSC413Final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pUbqqdYqPQ2S"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from math import ceil\n",
    "from torch.utils.benchmark import Timer\n",
    "import time\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vYIkbsUURRT1"
   },
   "outputs": [],
   "source": [
    "from shufflenet_alt import ShuffleNetV2, ShuffleNetSE, ShuffleNetSLE, init_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(file_path, model_name, batch_size, avg_inference_time, avg_batch_time, images_per_second, batches_per_second):\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    \n",
    "    with open(file_path, newline='', mode='a') as file:\n",
    "        csv_writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        if not file_exists:\n",
    "            csv_writer.writerow([\"Model\", \"Batch Size\", \"Average Inference Time(Image)\", \"Average Inference Time(Batch)\", \"Images/s\", \"Batches/s\"])\n",
    "        \n",
    "        csv_writer.writerow([model_name, batch_size, avg_inference_time, avg_batch_time, images_per_second, batches_per_second])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5132,
     "status": "ok",
     "timestamp": 1681320069891,
     "user": {
      "displayName": "Chang Yuan",
      "userId": "10478036312829595539"
     },
     "user_tz": 240
    },
    "id": "e-R6rUTEFQNn",
    "outputId": "b833ea1b-1910-4576-8e3a-6be0b28faa7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "<class 'shufflenet_alt.ShuffleNetSE'>\n",
      "Files already downloaded and verified\n",
      "Batch size: 32\n",
      "Average inference time per image: 0.000302 seconds\n",
      "Average inference time per batch: 0.009664 seconds\n",
      "Number of images per second: 3306.02\n",
      "Number of batches per second: 103.48\n",
      "Batch size: 64\n",
      "Average inference time per image: 0.000157 seconds\n",
      "Average inference time per batch: 0.009991 seconds\n",
      "Number of images per second: 6375.34\n",
      "Number of batches per second: 100.09\n",
      "Batch size: 128\n",
      "Average inference time per image: 0.000076 seconds\n",
      "Average inference time per batch: 0.009637 seconds\n",
      "Number of images per second: 13135.45\n",
      "Number of batches per second: 103.77\n"
     ]
    }
   ],
   "source": [
    "# Change batch size here\n",
    "batch_size_list = [32, 64, 128]\n",
    "\n",
    "model = ShuffleNetSE(net_size=1)\n",
    "\n",
    "# Change model path here\n",
    "model_state_dict = torch.load('se1/tmp/0099.pth')['mod']\n",
    "\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode and move it to the CUDA device\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "print(model.__class__)\n",
    "\n",
    "mean, std = (0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)\n",
    "\n",
    "# Define the transform to apply to the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# Create the test dataset\n",
    "test_set = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "num_images = len(test_set)\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "    # Create a DataLoader to generate batches of test data\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Warm up the model by running it a few times\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(test_loader):\n",
    "            if i == 5:\n",
    "                break\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "\n",
    "    total_elapsed_time = 0.0\n",
    "    total_samples = 0\n",
    "    total_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            start_time = time.time()\n",
    "            outputs = model(inputs)\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            total_elapsed_time += elapsed_time\n",
    "            total_samples += inputs.size(0)\n",
    "            total_batches += 1\n",
    "\n",
    "    # Calculate the average inference time per image\n",
    "    images_per_second = total_samples/total_elapsed_time\n",
    "    batches_per_second = total_batches/total_elapsed_time\n",
    "    avg_inference_time = total_elapsed_time / total_samples\n",
    "    avg_batch_time = total_elapsed_time / total_batches\n",
    "    print(f\"Average inference time per image: {avg_inference_time:.6f} seconds\")\n",
    "    print(f\"Average inference time per batch: {avg_batch_time:.6f} seconds\")\n",
    "    print(f\"Number of images per second: {images_per_second:.2f}\")\n",
    "    print(f\"Number of batches per second: {batches_per_second:.2f}\")\n",
    "    save_to_csv('inference_time.csv', model.__class__, batch_size, avg_inference_time, avg_batch_time, images_per_second, batches_per_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPxDdKSxo9RBBsIxUFt2/jJ",
   "provenance": [
    {
     "file_id": "1jxTlR8i_-Y7uDGX-ur4rONqmV-vXg7KE",
     "timestamp": 1681323777851
    }
   ],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
