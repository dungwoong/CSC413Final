---
title: "CSC413Final"
author: "Kevin W"
date: "09/04/2023"
output: html_document
---

```{r}
df1 <- read.csv("results/summary.csv")
df1
```
```{r, fig.width=7, fig.height=4}
library(tidyverse)

df1 %>% 
  mutate(batch_size = as.factor(batch_size)) %>% 
  ggplot(aes(x=lr, y=max_val_top1_acc, color=batch_size)) +
  geom_point() +
  geom_line() +
  theme_minimal() +
  facet_wrap(~model) +
  ylim(0.7, 0.95) +
  labs(title="Maxiumum validation accuracy by learning rate\n and batch size",
       y="Maximum top 1 accuracy",
       x="Learning Rate") +
  scale_x_continuous(labels = function(x) format(x, scientific = TRUE)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        plot.title = element_text(size=18, family=windowsFonts()$serif))
```

So low learning rate, smaller BS good because more gradient updates I guess, the lr is already low so the updates aren't dominated by noise. High lr large batch size is better because it becomes noise dominated. We find that 1e-3 batch size 64 yielded the best results, with 89.97% maximum validation accuracy achieved.

```{r}
df1 %>% filter(model == "SLE") %>% 
  mutate(batch_size = as.factor(batch_size)) %>% 
  ggplot(aes(x=lr, y=max_val_top1_acc, color=batch_size)) +
  geom_point() +
  geom_line() +
  theme_minimal() +
  ylim(0.7, 0.95) +
  labs(title="SLE model accuracy by learning rate and batch size",
       y="Maximum top 1 accuracy",
       x="Learning Rate")
```
Same results with SLE model, but we see that the batch size has a larger effect on the results with suboptimal learning rates and has less of an effect with the optimal(1e-3) learning rate. We were able to achieve slightly higher accuracy compared to the base model, of 90.19% maximum validation accuracy.

I think this was originally used in GAN, where it uses deeper layers with more channels to excite later layers, so the motivation to skip layers is valid. Here, deeper layers have less channels, so exciting later layers based on it probably doesn't have much of an effect, and takes a lot of computation.

```{r}
df1 %>% filter(model == "SE") %>% 
  mutate(batch_size = as.factor(batch_size)) %>% 
  ggplot(aes(x=lr, y=max_val_top1_acc, color=batch_size)) +
  geom_point() +
  geom_line() +
  theme_minimal() +
  ylim(0.7, 0.95) +
  labs(title="SE model accuracy by learning rate and batch size",
       y="Maximum top 1 accuracy",
       x="Learning Rate")
```

```{r}
# df2 <- read.csv("model_stats.csv")
# df2
```